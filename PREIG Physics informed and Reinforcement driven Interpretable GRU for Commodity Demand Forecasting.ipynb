{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a733820e-8d55-4454-a79e-1314a0816a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, copy, numpy as np, pandas as pd, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "file_path      = r\"\"\n",
    "new_data_path  = r\"\"\n",
    "\n",
    "\n",
    "feature_cols = [\n",
    "    \"Feature1\", \"Feature2\", \"Feature3\", \"Price\", \"Feature5\",\n",
    "    \"Feature6\", \"Feature7\", \"Feature8\", \"Feature9\", \"Feature10\", \"Feature11\"\n",
    "]\n",
    "target_col   = \"Demand\"\n",
    "assert \"Price\" in feature_cols, \"feature_cols must include 'Price'！\"\n",
    "\n",
    "\n",
    "normalize_y     = True\n",
    "lambda_phys     = 1.0          \n",
    "lambda_data     = 5\n",
    "population_size = 50            \n",
    "generations     = 5            \n",
    "nadam_lr0       = 0.01         \n",
    "nadam_betas     = (0.9, 0.999)\n",
    "lbfgs_lr        = 0.01         \n",
    "lbfgs_max_iter  = 20           \n",
    "gru_hidden      = 32           \n",
    "torch.manual_seed(42); np.random.seed(42)\n",
    "\n",
    "\n",
    "def maybe_make_dummy(path: str, rows: int = 120):\n",
    "    \"\"\"dummy if no real data\"\"\"\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    print(f\"[Info] {path} No real data\")\n",
    "    data = {c: np.random.rand(rows)*100 for c in feature_cols}\n",
    "    data[target_col] = 1000 - 5*data[\"Price\"] + 0.3*data[\"Feature1\"] \\\n",
    "                       -0.2*data[\"Feature2\"] + np.random.randn(rows)*25\n",
    "    pd.DataFrame(data).to_excel(path, index=False)\n",
    "\n",
    "maybe_make_dummy(file_path)\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "X = df[feature_cols].astype(\"float32\").values\n",
    "y = df[target_col].astype(\"float32\").values\n",
    "N, d = X.shape\n",
    "price_idx = feature_cols.index(\"Price\")\n",
    "\n",
    "\n",
    "scaler_X = StandardScaler().fit(X)\n",
    "X_scaled = scaler_X.transform(X)\n",
    "\n",
    "if normalize_y:\n",
    "    scaler_y = StandardScaler().fit(y.reshape(-1,1))\n",
    "    y_scaled = scaler_y.transform(y.reshape(-1,1)).reshape(-1)\n",
    "else:\n",
    "    y_scaled = y\n",
    "\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_scaled, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "\n",
    "class GRUPINN(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: (batch, feat)  => unsqueeze(1) → GRU(seq=1) → fc(1)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim: int, hidden: int = 64):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=input_dim,\n",
    "                          hidden_size=hidden,\n",
    "                          batch_first=True)\n",
    "        self.fc  = nn.Linear(hidden, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (batch, feat)  →  (batch, 1, feat)\n",
    "        out, _ = self.gru(x.unsqueeze(1))\n",
    "        return self.fc(out[:, -1, :])      \n",
    "\n",
    "def create_model():\n",
    "    return GRUPINN(d, gru_hidden)\n",
    "\n",
    "\n",
    "def calc_phys_loss(preds, inputs):\n",
    "    \"\"\"∂pred/∂Price  ≤ 0\"\"\"\n",
    "    grads = torch.autograd.grad(preds, inputs,\n",
    "                                grad_outputs=torch.ones_like(preds),\n",
    "                                create_graph=True)[0]\n",
    "    price_grads = grads[:, price_idx]          # (batch,)\n",
    "    return torch.mean(torch.clamp(price_grads, min=0.0)**2)\n",
    "\n",
    "def train_one(model, X_train, y_train, epochs: int, lr: float):\n",
    "    model.train()\n",
    "    opt_nadam = optim.NAdam(model.parameters(), lr=lr, betas=nadam_betas)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        opt_nadam.zero_grad()\n",
    "        preds = model(X_train)\n",
    "        data_loss = torch.mean((preds - y_train)**2)\n",
    "\n",
    "        X_req = X_train.detach().clone().requires_grad_(True)\n",
    "        phys_loss = calc_phys_loss(model(X_req), X_req)\n",
    "\n",
    "        loss = lambda_data*data_loss + lambda_phys*phys_loss\n",
    "        loss.backward()\n",
    "        opt_nadam.step()\n",
    "\n",
    " \n",
    "    opt_lbfgs = optim.LBFGS(model.parameters(),\n",
    "                            lr=lbfgs_lr,\n",
    "                            max_iter=lbfgs_max_iter)\n",
    "\n",
    "    def closure():\n",
    "        opt_lbfgs.zero_grad()\n",
    "        preds = model(X_train)\n",
    "        data_l = torch.mean((preds - y_train)**2)\n",
    "        X_req2 = X_train.detach().clone().requires_grad_(True)\n",
    "        phys_l = calc_phys_loss(model(X_req2), X_req2)\n",
    "        total  = lambda_data*data_l + lambda_phys*phys_l\n",
    "        total.backward()\n",
    "        return total\n",
    "\n",
    "    opt_lbfgs.step(closure)\n",
    "\n",
    "def total_loss(model, X_eval, y_eval):\n",
    "    with torch.no_grad():\n",
    "        data_l = torch.mean((model(X_eval) - y_eval)**2)\n",
    "    X_req = X_eval.detach().clone().requires_grad_(True)\n",
    "    phys_l = calc_phys_loss(model(X_req), X_req).detach()\n",
    "    return (lambda_data*data_l + lambda_phys*phys_l).item()\n",
    "\n",
    "\n",
    "population = [\n",
    "    {\"model\": create_model(),\n",
    "     \"lr\":    nadam_lr0 * (0.8 + 0.4*np.random.rand())}\n",
    "    for _ in range(population_size)\n",
    "]\n",
    "\n",
    "for gen in range(1, generations+1):\n",
    "    print(f\"\\n=== PBT Generation {gen}/{generations} ===\")\n",
    "    losses = []\n",
    "    for i, indiv in enumerate(population, 1):\n",
    "        train_one(indiv[\"model\"], X_tensor, y_tensor,\n",
    "                  epochs=30, lr=indiv[\"lr\"])\n",
    "        loss_i = total_loss(indiv[\"model\"], X_tensor, y_tensor)\n",
    "        losses.append(loss_i)\n",
    "        print(f\"  ▸ indiv{i:02d} | lr={indiv['lr']:.5f} | loss={loss_i:.6f}\")\n",
    "\n",
    "    best_idx, worst_idx = int(np.argmin(losses)), int(np.argmax(losses))\n",
    "    if best_idx != worst_idx:\n",
    "        \n",
    "        population[worst_idx][\"model\"].load_state_dict(\n",
    "            copy.deepcopy(population[best_idx][\"model\"].state_dict()))\n",
    "        new_lr = population[best_idx][\"lr\"] * (0.8 + 0.4*np.random.rand())\n",
    "        population[worst_idx][\"lr\"] = new_lr\n",
    "        print(f\"  ↻  Clone best({best_idx+1}) → worst({worst_idx+1}), \"\n",
    "              f\"mut lr → {new_lr:.5f}\")\n",
    "\n",
    "\n",
    "best_idx = int(np.argmin([total_loss(p[\"model\"], X_tensor, y_tensor)\n",
    "                          for p in population]))\n",
    "best_model = population[best_idx][\"model\"]\n",
    "torch.save(best_model.state_dict(), \"best_demand_model.pth\")\n",
    "print(f\"\\n✔ Training finished. Best indiv = {best_idx+1}  \"\n",
    "      f\"→ saved to best_demand_model.pth\")\n",
    "\n",
    "\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_train_std = best_model(X_tensor)\n",
    "\n",
    "y_pred_train = (scaler_y.inverse_transform(y_pred_train_std.numpy())\n",
    "                if normalize_y else y_pred_train_std.numpy())\n",
    "\n",
    "df[\"Predicted\"] = y_pred_train\n",
    "df[\"Error\"]     = df[target_col] - df[\"Predicted\"]\n",
    "df.to_excel(\"train_with_predictions Crude Oil.xlsx\", index=False)\n",
    "print(\"saved as train_with_predictions.xlsx\")\n",
    "\n",
    "\n",
    "maybe_make_dummy(new_data_path, rows=10)\n",
    "new_df = pd.read_excel(new_data_path)\n",
    "\n",
    "X_new_std = scaler_X.transform(new_df[feature_cols].astype(\"float32\"))\n",
    "X_new_tensor = torch.tensor(X_new_std, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred_new_std = best_model(X_new_tensor)\n",
    "y_pred_new = (scaler_y.inverse_transform(y_pred_new_std.numpy())\n",
    "              if normalize_y else y_pred_new_std.numpy())\n",
    "new_df[\"PredictedDemand\"] = y_pred_new\n",
    "new_df.to_excel(\"test_with_predictions.xlsx\", index=False)\n",
    "print(\"saved as test_with_predictions.xlsx\")  usyd\n",
    "\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (11,5)\n",
    "plt.figure()\n",
    "plt.plot(df.index, df[target_col], label=\"Train-Actual\", marker=\"o\")\n",
    "plt.plot(df.index, df[\"Predicted\"], label=\"Train-Pred\",  marker=\"x\")\n",
    "plt.title(\"Training – Actual vs Predicted\"); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure()\n",
    "if target_col in new_df.columns:\n",
    "    plt.plot(new_df.index, new_df[target_col], label=\"Test-Actual\", marker=\"o\")\n",
    "plt.plot(new_df.index, new_df[\"PredictedDemand\"], label=\"Test-Pred\", marker=\"x\")\n",
    "plt.title(\"Test / Prediction – Actual vs Predicted\"); plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
