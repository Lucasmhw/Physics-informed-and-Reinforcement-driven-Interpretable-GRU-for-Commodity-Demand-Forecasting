{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f433849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]  No real data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No engine for filetype: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOptionError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1136\u001b[0m, in \u001b[0;36mExcelWriter.__new__\u001b[1;34m(cls, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1136\u001b[0m     engine \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_option(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.excel.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.writer\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\_config\\config.py:274\u001b[0m, in \u001b[0;36mCallableDynamicDoc.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m--> 274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\_config\\config.py:146\u001b[0m, in \u001b[0;36m_get_option\u001b[1;34m(pat, silent)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_option\u001b[39m(pat: \u001b[38;5;28mstr\u001b[39m, silent: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 146\u001b[0m     key \u001b[38;5;241m=\u001b[39m _get_single_key(pat, silent)\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;66;03m# walk the nested dict\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\_config\\config.py:132\u001b[0m, in \u001b[0;36m_get_single_key\u001b[1;34m(pat, silent)\u001b[0m\n\u001b[0;32m    131\u001b[0m         _warn_if_deprecated(pat)\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OptionError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such keys(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(pat)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(keys) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mOptionError\u001b[0m: No such keys(s): 'io.excel..writer'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 44\u001b[0m\n\u001b[0;32m     40\u001b[0m     data[target_col] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m5\u001b[39m\u001b[38;5;241m*\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.3\u001b[39m\u001b[38;5;241m*\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \\\n\u001b[0;32m     41\u001b[0m                        \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.2\u001b[39m\u001b[38;5;241m*\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature2\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(rows)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m25\u001b[39m\n\u001b[0;32m     42\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\u001b[38;5;241m.\u001b[39mto_excel(path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 44\u001b[0m maybe_make_dummy(file_path)\n\u001b[0;32m     45\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(file_path)\n\u001b[0;32m     47\u001b[0m X \u001b[38;5;241m=\u001b[39m df[feature_cols]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n",
      "Cell \u001b[1;32mIn[1], line 42\u001b[0m, in \u001b[0;36mmaybe_make_dummy\u001b[1;34m(path, rows)\u001b[0m\n\u001b[0;32m     39\u001b[0m data \u001b[38;5;241m=\u001b[39m {c: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(rows)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m feature_cols}\n\u001b[0;32m     40\u001b[0m data[target_col] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m5\u001b[39m\u001b[38;5;241m*\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.3\u001b[39m\u001b[38;5;241m*\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \\\n\u001b[0;32m     41\u001b[0m                    \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.2\u001b[39m\u001b[38;5;241m*\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature2\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(rows)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m25\u001b[39m\n\u001b[1;32m---> 42\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\u001b[38;5;241m.\u001b[39mto_excel(path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:2417\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2404\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2406\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2407\u001b[0m     df,\n\u001b[0;32m   2408\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2415\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2416\u001b[0m )\n\u001b[1;32m-> 2417\u001b[0m formatter\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[0;32m   2418\u001b[0m     excel_writer,\n\u001b[0;32m   2419\u001b[0m     sheet_name\u001b[38;5;241m=\u001b[39msheet_name,\n\u001b[0;32m   2420\u001b[0m     startrow\u001b[38;5;241m=\u001b[39mstartrow,\n\u001b[0;32m   2421\u001b[0m     startcol\u001b[38;5;241m=\u001b[39mstartcol,\n\u001b[0;32m   2422\u001b[0m     freeze_panes\u001b[38;5;241m=\u001b[39mfreeze_panes,\n\u001b[0;32m   2423\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m   2424\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   2425\u001b[0m     engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m   2426\u001b[0m )\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\io\\formats\\excel.py:943\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    941\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 943\u001b[0m     writer \u001b[38;5;241m=\u001b[39m ExcelWriter(\n\u001b[0;32m    944\u001b[0m         writer,\n\u001b[0;32m    945\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    946\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    947\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    948\u001b[0m     )\n\u001b[0;32m    949\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1140\u001b[0m, in \u001b[0;36mExcelWriter.__new__\u001b[1;34m(cls, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1138\u001b[0m             engine \u001b[38;5;241m=\u001b[39m get_default_engine(ext, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwriter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1139\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 1140\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo engine for filetype: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: No engine for filetype: ''"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, copy, numpy as np, pandas as pd, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "file_path      = r\"\"\n",
    "new_data_path  = r\"\"\n",
    "\n",
    "\n",
    "feature_cols = [\n",
    "    \"Feature1\", \"Feature2\", \"Feature3\", \"Price\", \"Feature5\",\n",
    "    \"Feature6\", \"Feature7\", \"Feature8\", \"Feature9\", \"Feature10\", \"Feature11\"\n",
    "]\n",
    "target_col   = \"Demand\"\n",
    "assert \"Price\" in feature_cols, \"feature_cols must include 'Price'！\"\n",
    "\n",
    "\n",
    "normalize_y     = True\n",
    "lambda_phys     = 1.0          \n",
    "lambda_data     = 5\n",
    "population_size = 50            \n",
    "generations     = 5            \n",
    "nadam_lr0       = 0.01         \n",
    "nadam_betas     = (0.9, 0.999)\n",
    "lbfgs_lr        = 0.01         \n",
    "lbfgs_max_iter  = 20           \n",
    "gru_hidden      = 32           \n",
    "torch.manual_seed(42); np.random.seed(42)\n",
    "\n",
    "\n",
    "def maybe_make_dummy(path: str, rows: int = 120):\n",
    "    \"\"\"dummy if no real data\"\"\"\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    print(f\"[Info] {path} No real data\")\n",
    "    data = {c: np.random.rand(rows)*100 for c in feature_cols}\n",
    "    data[target_col] = 1000 - 5*data[\"Price\"] + 0.3*data[\"Feature1\"] \\\n",
    "                       -0.2*data[\"Feature2\"] + np.random.randn(rows)*25\n",
    "    pd.DataFrame(data).to_excel(path, index=False)\n",
    "\n",
    "maybe_make_dummy(file_path)\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "X = df[feature_cols].astype(\"float32\").values\n",
    "y = df[target_col].astype(\"float32\").values\n",
    "N, d = X.shape\n",
    "price_idx = feature_cols.index(\"Price\")\n",
    "\n",
    "\n",
    "scaler_X = StandardScaler().fit(X)\n",
    "X_scaled = scaler_X.transform(X)\n",
    "\n",
    "if normalize_y:\n",
    "    scaler_y = StandardScaler().fit(y.reshape(-1,1))\n",
    "    y_scaled = scaler_y.transform(y.reshape(-1,1)).reshape(-1)\n",
    "else:\n",
    "    y_scaled = y\n",
    "\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_scaled, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "\n",
    "class GRUPINN(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: (batch, feat)  => unsqueeze(1) → GRU(seq=1) → fc(1)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim: int, hidden: int = 64):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=input_dim,\n",
    "                          hidden_size=hidden,\n",
    "                          batch_first=True)\n",
    "        self.fc  = nn.Linear(hidden, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (batch, feat)  →  (batch, 1, feat)\n",
    "        out, _ = self.gru(x.unsqueeze(1))\n",
    "        return self.fc(out[:, -1, :])      \n",
    "\n",
    "def create_model():\n",
    "    return GRUPINN(d, gru_hidden)\n",
    "\n",
    "\n",
    "def calc_phys_loss(preds, inputs):\n",
    "    \"\"\"∂pred/∂Price  ≤ 0\"\"\"\n",
    "    grads = torch.autograd.grad(preds, inputs,\n",
    "                                grad_outputs=torch.ones_like(preds),\n",
    "                                create_graph=True)[0]\n",
    "    price_grads = grads[:, price_idx]          # (batch,)\n",
    "    return torch.mean(torch.clamp(price_grads, min=0.0)**2)\n",
    "\n",
    "def train_one(model, X_train, y_train, epochs: int, lr: float):\n",
    "    model.train()\n",
    "    opt_nadam = optim.NAdam(model.parameters(), lr=lr, betas=nadam_betas)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        opt_nadam.zero_grad()\n",
    "        preds = model(X_train)\n",
    "        data_loss = torch.mean((preds - y_train)**2)\n",
    "\n",
    "        X_req = X_train.detach().clone().requires_grad_(True)\n",
    "        phys_loss = calc_phys_loss(model(X_req), X_req)\n",
    "\n",
    "        loss = lambda_data*data_loss + lambda_phys*phys_loss\n",
    "        loss.backward()\n",
    "        opt_nadam.step()\n",
    "\n",
    " \n",
    "    opt_lbfgs = optim.LBFGS(model.parameters(),\n",
    "                            lr=lbfgs_lr,\n",
    "                            max_iter=lbfgs_max_iter)\n",
    "\n",
    "    def closure():\n",
    "        opt_lbfgs.zero_grad()\n",
    "        preds = model(X_train)\n",
    "        data_l = torch.mean((preds - y_train)**2)\n",
    "        X_req2 = X_train.detach().clone().requires_grad_(True)\n",
    "        phys_l = calc_phys_loss(model(X_req2), X_req2)\n",
    "        total  = lambda_data*data_l + lambda_phys*phys_l\n",
    "        total.backward()\n",
    "        return total\n",
    "\n",
    "    opt_lbfgs.step(closure)\n",
    "\n",
    "def total_loss(model, X_eval, y_eval):\n",
    "    with torch.no_grad():\n",
    "        data_l = torch.mean((model(X_eval) - y_eval)**2)\n",
    "    X_req = X_eval.detach().clone().requires_grad_(True)\n",
    "    phys_l = calc_phys_loss(model(X_req), X_req).detach()\n",
    "    return (lambda_data*data_l + lambda_phys*phys_l).item()\n",
    "\n",
    "\n",
    "population = [\n",
    "    {\"model\": create_model(),\n",
    "     \"lr\":    nadam_lr0 * (0.8 + 0.4*np.random.rand())}\n",
    "    for _ in range(population_size)\n",
    "]\n",
    "\n",
    "for gen in range(1, generations+1):\n",
    "    print(f\"\\n=== PBT Generation {gen}/{generations} ===\")\n",
    "    losses = []\n",
    "    for i, indiv in enumerate(population, 1):\n",
    "        train_one(indiv[\"model\"], X_tensor, y_tensor,\n",
    "                  epochs=30, lr=indiv[\"lr\"])\n",
    "        loss_i = total_loss(indiv[\"model\"], X_tensor, y_tensor)\n",
    "        losses.append(loss_i)\n",
    "        print(f\"  ▸ indiv{i:02d} | lr={indiv['lr']:.5f} | loss={loss_i:.6f}\")\n",
    "\n",
    "    best_idx, worst_idx = int(np.argmin(losses)), int(np.argmax(losses))\n",
    "    if best_idx != worst_idx:\n",
    "        \n",
    "        population[worst_idx][\"model\"].load_state_dict(\n",
    "            copy.deepcopy(population[best_idx][\"model\"].state_dict()))\n",
    "        new_lr = population[best_idx][\"lr\"] * (0.8 + 0.4*np.random.rand())\n",
    "        population[worst_idx][\"lr\"] = new_lr\n",
    "        print(f\"  ↻  Clone best({best_idx+1}) → worst({worst_idx+1}), \"\n",
    "              f\"mut lr → {new_lr:.5f}\")\n",
    "\n",
    "\n",
    "best_idx = int(np.argmin([total_loss(p[\"model\"], X_tensor, y_tensor)\n",
    "                          for p in population]))\n",
    "best_model = population[best_idx][\"model\"]\n",
    "torch.save(best_model.state_dict(), \"best_demand_model.pth\")\n",
    "print(f\"\\n✔ Training finished. Best indiv = {best_idx+1}  \"\n",
    "      f\"→ saved to best_demand_model Crude Oil.pth\")\n",
    "\n",
    "\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_train_std = best_model(X_tensor)\n",
    "\n",
    "y_pred_train = (scaler_y.inverse_transform(y_pred_train_std.numpy())\n",
    "                if normalize_y else y_pred_train_std.numpy())\n",
    "\n",
    "df[\"Predicted\"] = y_pred_train\n",
    "df[\"Error\"]     = df[target_col] - df[\"Predicted\"]\n",
    "df.to_excel(\"train_with_predictions Crude Oil.xlsx\", index=False)\n",
    "print(\"saved as train_with_predictions.xlsx\")\n",
    "\n",
    "\n",
    "maybe_make_dummy(new_data_path, rows=10)\n",
    "new_df = pd.read_excel(new_data_path)\n",
    "\n",
    "X_new_std = scaler_X.transform(new_df[feature_cols].astype(\"float32\"))\n",
    "X_new_tensor = torch.tensor(X_new_std, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred_new_std = best_model(X_new_tensor)\n",
    "y_pred_new = (scaler_y.inverse_transform(y_pred_new_std.numpy())\n",
    "              if normalize_y else y_pred_new_std.numpy())\n",
    "new_df[\"PredictedDemand\"] = y_pred_new\n",
    "new_df.to_excel(\"test_with_predictions.xlsx\", index=False)\n",
    "print(\"saved as test_with_predictions.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (11,5)\n",
    "plt.figure()\n",
    "plt.plot(df.index, df[target_col], label=\"Train-Actual\", marker=\"o\")\n",
    "plt.plot(df.index, df[\"Predicted\"], label=\"Train-Pred\",  marker=\"x\")\n",
    "plt.title(\"Training – Actual vs Predicted\"); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure()\n",
    "if target_col in new_df.columns:\n",
    "    plt.plot(new_df.index, new_df[target_col], label=\"Test-Actual\", marker=\"o\")\n",
    "plt.plot(new_df.index, new_df[\"PredictedDemand\"], label=\"Test-Pred\", marker=\"x\")\n",
    "plt.title(\"Test / Prediction – Actual vs Predicted\"); plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
